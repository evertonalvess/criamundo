/**
 * AI Manager - Gerenciador de Integra√ß√£o com IA
 * Respons√°vel por gerar hist√≥rias, imagens e √°udio usando IA
 */

class AIManager {
    constructor() {
        this.config = null;
        this.isInitialized = false;
        this.currentStory = null;
        this.apiKey = null;
        this.init();
    }

    async init() {
        try {
            console.log('üîß AI Manager - Iniciando...');
            const response = await fetch('/config/ai-config.json');
            this.config = await response.json();
            console.log('üìã Configura√ß√£o carregada:', this.config);
            
            // Verificar se a API key est√° configurada
            this.apiKey = this.config.openai.apiKey;
            console.log('üîë API Key encontrada:', this.apiKey ? 'Sim' : 'N√£o');
            
            if (this.apiKey && this.apiKey !== 'YOUR_OPENAI_API_KEY_HERE') {
                this.isInitialized = true;
                console.log('‚úÖ AI Manager inicializado com OpenAI');
            } else {
                console.log('‚ö†Ô∏è OpenAI n√£o configurado - usando modo fallback');
            }
        } catch (error) {
            console.error('‚ùå Erro ao carregar configura√ß√£o da IA:', error);
        }
    }

    getDefaultConfig() {
        return {
            ai: { enabled: false },
            features: {
                voiceRecognition: { enabled: false },
                textToSpeech: { enabled: false },
                imageGeneration: { enabled: false }
            },
            fallback: { enableOfflineMode: true }
        };
    }

    /**
     * Gera uma hist√≥ria usando IA
     * @param {Object} params - Par√¢metros para gera√ß√£o
     * @returns {Promise<Object>} Hist√≥ria gerada
     */
    async generateStory(params = {}) {
        console.log('üîç AI Manager - generateStory chamado com params:', params);
        
        if (!this.isInitialized) {
            console.log('‚ö†Ô∏è AI Manager n√£o inicializado - usando fallback');
            return this.getFallbackStory(params);
        }

        try {
            console.log('üöÄ Chamando OpenAI API...');
            const prompt = this.buildPrompt(params);
            console.log('üìù Prompt gerado:', prompt);
            
            const story = await this.callOpenAI(prompt);
            console.log('‚úÖ Resposta da OpenAI:', story);
            
            const parsedStory = this.parseStoryResponse(story);
            console.log('üìñ Hist√≥ria processada:', parsedStory);
            
            return parsedStory;
        } catch (error) {
            console.error('‚ùå Erro ao gerar hist√≥ria com OpenAI:', error);
            return this.getFallbackStory(params);
        }
    }

    /**
     * Gera imagem para a hist√≥ria
     * @param {string} storyTitle - T√≠tulo da hist√≥ria
     * @param {string} scene - Cena para ilustrar
     * @returns {Promise<string>} URL da imagem gerada
     */
    async generateImage(storyTitle, scene) {
        if (!this.config.features.imageGeneration.enabled) {
            return this.getFallbackImage(storyTitle);
        }

        try {
            const imageParams = {
                titulo: storyTitle,
                cena: scene
            };

            const imageUrl = await this.callAIProvider('imageGeneration', imageParams);
            return imageUrl;
        } catch (error) {
            console.error('Erro ao gerar imagem:', error);
            return this.getFallbackImage(storyTitle);
        }
    }

    /**
     * Gera √°udio para a hist√≥ria
     * @param {string} storyTitle - T√≠tulo da hist√≥ria
     * @param {string} storyText - Texto da hist√≥ria
     * @returns {Promise<Blob>} √Åudio gerado
     */
    async generateAudio(storyTitle, storyText) {
        if (!this.config.features.textToSpeech.enabled) {
            return this.getFallbackAudio();
        }

        try {
            const audioParams = {
                titulo: storyTitle,
                texto: storyText
            };

            const audioBlob = await this.callAIProvider('audioGeneration', audioParams);
            return audioBlob;
        } catch (error) {
            console.error('Erro ao gerar √°udio:', error);
            return this.getFallbackAudio();
        }
    }

    /**
     * Chama o provedor de IA configurado
     * @param {string} task - Tipo de tarefa
     * @param {Object} params - Par√¢metros
     * @returns {Promise<any>} Resultado da IA
     */
    async callAIProvider(task, params) {
        const providers = this.config.ai.providers;
        
        // Verificar qual provedor est√° habilitado
        for (const [providerName, provider] of Object.entries(providers)) {
            if (provider.enabled) {
                return await this.callProvider(providerName, task, params);
            }
        }

        throw new Error('Nenhum provedor de IA habilitado');
    }

    /**
     * Chama um provedor espec√≠fico
     * @param {string} providerName - Nome do provedor
     * @param {string} task - Tipo de tarefa
     * @param {Object} params - Par√¢metros
     * @returns {Promise<any>} Resultado
     */
    async callProvider(providerName, task, params) {
        switch (providerName) {
            case 'openai':
                return await this.callOpenAI(task, params);
            case 'anthropic':
                return await this.callAnthropic(task, params);
            case 'local':
                return await this.callLocal(task, params);
            default:
                throw new Error(`Provedor ${providerName} n√£o suportado`);
        }
    }

    /**
     * Chama OpenAI API
     */
    async callOpenAI(prompt) {
        const response = await fetch('https://api.openai.com/v1/chat/completions', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'Authorization': `Bearer ${this.apiKey}`
            },
            body: JSON.stringify({
                model: this.config.openai.model,
                messages: [
                    {
                        role: 'system',
                        content: this.config.openai.systemPrompt
                    },
                    {
                        role: 'user',
                        content: prompt
                    }
                ],
                max_tokens: this.config.openai.maxTokens,
                temperature: this.config.openai.temperature
            })
        });

        if (!response.ok) {
            throw new Error(`OpenAI API error: ${response.status}`);
        }

        const data = await response.json();
        return data.choices[0].message.content;
    }

    /**
     * Chama Anthropic API
     */
    async callAnthropic(task, params) {
        const provider = this.config.ai.providers.anthropic;
        const prompt = this.buildPrompt(task, params);

        const response = await fetch('https://api.anthropic.com/v1/messages', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                'x-api-key': provider.apiKey,
                'anthropic-version': '2023-06-01'
            },
            body: JSON.stringify({
                model: provider.model,
                max_tokens: provider.maxTokens,
                messages: [
                    { role: 'user', content: prompt }
                ]
            })
        });

        if (!response.ok) {
            throw new Error(`Anthropic API error: ${response.status}`);
        }

        const data = await response.json();
        return data.content[0].text;
    }

    /**
     * Chama API local
     */
    async callLocal(task, params) {
        const provider = this.config.ai.providers.local;
        const prompt = this.buildPrompt(task, params);

        const response = await fetch(provider.endpoint, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                model: provider.model,
                prompt: prompt,
                task: task
            })
        });

        if (!response.ok) {
            throw new Error(`Local API error: ${response.status}`);
        }

        const data = await response.json();
        return data.result;
    }

    /**
     * Constr√≥i o prompt para a tarefa
     */
    buildPrompt(params) {
        let prompt = this.config.openai.systemPrompt + '\n\n';
        
        if (params.tema) {
            prompt += `Tema principal: ${params.tema}\n`;
        }
        if (params.personagens) {
            prompt += `Personagens: ${params.personagens}\n`;
        }
        if (params.cenario) {
            prompt += `Cen√°rio: ${params.cenario}\n`;
        }
        if (params.voiceText) {
            prompt += `Inspira√ß√£o da crian√ßa: "${params.voiceText}"\n`;
        }

        prompt += '\nCrie uma hist√≥ria m√°gica e envolvente baseada nos elementos acima.';
        
        return prompt;
    }

    /**
     * Formata a hist√≥ria gerada
     */
    formatStory(rawStory) {
        // Dividir em par√°grafos
        const paragraphs = rawStory.split('\n\n').filter(p => p.trim());
        
        return {
            id: this.generateStoryId(),
            title: this.extractTitle(paragraphs[0]),
            paragraphs: paragraphs.map((p, index) => ({
                id: index + 1,
                text: p.trim(),
                illustration: `scene-${index + 1}`,
                audioDuration: Math.ceil(p.split(' ').length / 3) // Estimativa de dura√ß√£o
            })),
            metadata: {
                createdAt: new Date().toISOString(),
                generatedBy: 'ai',
                wordCount: rawStory.split(' ').length
            }
        };
    }

    /**
     * Gera ID √∫nico para hist√≥ria
     */
    generateStoryId() {
        return 'story-' + Date.now() + '-' + Math.random().toString(36).substr(2, 9);
    }

    /**
     * Extrai t√≠tulo da primeira linha
     */
    extractTitle(firstParagraph) {
        // Remove marcadores como "T√≠tulo:" ou "#"
        return firstParagraph.replace(/^(T√≠tulo|Title|#)\s*:?\s*/i, '').trim();
    }

    /**
     * Retorna tema aleat√≥rio
     */
    getRandomTheme() {
        const themes = this.config.ai.storyStructure.themes;
        return themes[Math.floor(Math.random() * themes.length)];
    }

    /**
     * Retorna personagens aleat√≥rios
     */
    getRandomCharacters() {
        const characterTypes = this.config.ai.storyStructure.characterTypes;
        const type = characterTypes[Math.floor(Math.random() * characterTypes.length)];
        
        const characterExamples = {
            'animais': ['um gato e um cachorro', 'uma coruja e um esquilo', 'um le√£o e um rato'],
            'criaturas m√°gicas': ['um drag√£o e uma fada', 'um unic√≥rnio e um gnomo', 'uma sereia e um trit√£o'],
            'crian√ßas': ['duas crian√ßas amigas', 'um menino e uma menina', 'tr√™s amigos'],
            'super-her√≥is': ['um super-her√≥i e seu ajudante', 'duas hero√≠nas', 'um her√≥i e uma vil√£ redimida'],
            'princesas e pr√≠ncipes': ['uma princesa e um pr√≠ncipe', 'duas princesas', 'um pr√≠ncipe e seu cavalo'],
            'profissionais': ['um m√©dico e um professor', 'um bombeiro e um policial', 'um astronauta e um cientista']
        };

        return characterExamples[type] ? 
            characterExamples[type][Math.floor(Math.random() * characterExamples[type].length)] :
            'personagens m√°gicos';
    }

    /**
     * Retorna hist√≥ria de fallback
     */
    getFallbackStory(params = {}) {
        const fallbackStories = this.config.fallback.stories;
        const randomStory = fallbackStories[Math.floor(Math.random() * fallbackStories.length)];
        
        // Personalizar hist√≥ria de fallback se houver par√¢metros
        if (params.tema || params.personagens || params.cenario) {
            return this.personalizeFallbackStory(randomStory, params);
        }
        
        return randomStory;
    }

    personalizeFallbackStory(story, params) {
        let personalizedStory = { ...story };
        
        if (params.tema) {
            personalizedStory.title = `${personalizedStory.title} - ${params.tema}`;
        }
        
        if (params.personagens) {
            // Substituir personagens na hist√≥ria
            personalizedStory.paragraphs = personalizedStory.paragraphs.map(paragraph => {
                return paragraph.replace(/drag√£o/g, params.personagens)
                              .replace(/fada/g, params.personagens);
            });
        }
        
        return personalizedStory;
    }

    /**
     * Retorna imagem de fallback
     */
    getFallbackImage(storyTitle) {
        // Retorna uma ilustra√ß√£o baseada em emojis
        return `data:image/svg+xml,${encodeURIComponent(`
            <svg width="400" height="300" xmlns="http://www.w3.org/2000/svg">
                <rect width="400" height="300" fill="#f0f8ff"/>
                <text x="200" y="150" font-family="Arial" font-size="48" text-anchor="middle" fill="#333">
                    üé®
                </text>
                <text x="200" y="200" font-family="Arial" font-size="16" text-anchor="middle" fill="#666">
                    ${storyTitle}
                </text>
            </svg>
        `)}`;
    }

    /**
     * Retorna √°udio de fallback
     */
    getFallbackAudio() {
        // Retorna um √°udio silencioso de 1 segundo
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const oscillator = audioContext.createOscillator();
        const gainNode = audioContext.createGain();
        
        oscillator.connect(gainNode);
        gainNode.connect(audioContext.destination);
        
        gainNode.gain.setValueAtTime(0, audioContext.currentTime);
        
        oscillator.start(audioContext.currentTime);
        oscillator.stop(audioContext.currentTime + 1);
        
        return new Blob([], { type: 'audio/wav' });
    }

    /**
     * Verifica se a IA est√° dispon√≠vel
     */
    isAvailable() {
        return this.isInitialized;
    }

    /**
     * Obt√©m mensagens de carregamento
     */
    getLoadingMessages() {
        return this.config.ui.loadingMessages || [
            'Pensando em uma hist√≥ria m√°gica...',
            'Criando personagens especiais...',
            'Finalizando sua hist√≥ria...'
        ];
    }

    /**
     * Obt√©m mensagem de erro
     */
    getErrorMessage(type = 'general') {
        const messages = this.config.ui.errorMessages;
        return messages[type] || messages.general || 'Algo deu errado. Tente novamente!';
    }

    parseStoryResponse(response) {
        try {
            // Tentar extrair t√≠tulo e par√°grafos da resposta
            const lines = response.split('\n').filter(line => line.trim());
            
            let title = 'Hist√≥ria M√°gica';
            let paragraphs = [];
            
            for (let i = 0; i < lines.length; i++) {
                const line = lines[i].trim();
                
                // Procurar por t√≠tulo (primeira linha ou linha que come√ßa com #)
                if (i === 0 || line.startsWith('#') || line.startsWith('T√≠tulo:')) {
                    title = line.replace(/^[#\s]*T√≠tulo:\s*/, '').replace(/^[#\s]+/, '');
                    continue;
                }
                
                // Ignorar linhas vazias ou marcadores
                if (line === '' || line.startsWith('-') || line.startsWith('*')) {
                    continue;
                }
                
                // Adicionar como par√°grafo se n√£o for muito curto
                if (line.length > 10) {
                    paragraphs.push(line);
                }
            }
            
            // Se n√£o encontrou par√°grafos, dividir por pontos
            if (paragraphs.length === 0) {
                paragraphs = response.split('.').filter(p => p.trim().length > 10);
            }
            
            // Limitar a 4 par√°grafos
            paragraphs = paragraphs.slice(0, 4);
            
            return {
                title: title,
                paragraphs: paragraphs
            };
        } catch (error) {
            console.error('Erro ao processar resposta da IA:', error);
            return this.getFallbackStory();
        }
    }

    getStatus() {
        return {
            initialized: this.isInitialized,
            hasApiKey: !!this.apiKey && this.apiKey !== 'YOUR_OPENAI_API_KEY_HERE',
            config: this.config ? 'loaded' : 'not_loaded'
        };
    }
}

// Exportar para uso global
window.AIManager = AIManager; 